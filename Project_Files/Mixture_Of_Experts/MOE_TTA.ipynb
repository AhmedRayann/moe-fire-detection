{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38fde9f0",
   "metadata": {},
   "source": [
    "##  Enhancing MoE Performance with Test-Time Augmentation (TTA)\n",
    "\n",
    "In this notebook, we explore the use of **Test-Time Augmentation (TTA)** to further improve the performance of our **Mixture of Experts (MoE)** model for fire detection.\n",
    "\n",
    "###  Objective:\n",
    "To boost the robustness and accuracy of the MoE system by applying augmentations during inference and aggregating predictions to form a more reliable output.\n",
    "\n",
    "###  What is TTA?\n",
    "**Test-Time Augmentation** involves applying a set of transformations (e.g., horizontal flip, scaling, rotation) to the input image at inference time. The model generates predictions on each augmented version, and these predictions are then combined — typically via averaging or ensembling — to yield a final result.\n",
    "\n",
    "\n",
    "\n",
    "###  This Notebook Covers:\n",
    "- Integration of TTA within the MoE pipeline.\n",
    "- Running inference using multiple augmented views of the input.\n",
    "- Fusing predictions using **Weighted Box Fusion (WBF)** to obtain the final output.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e207484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "from PIL import ImageEnhance\n",
    "import numpy as np\n",
    "def horizontal_flip(image):\n",
    "    return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "def adjust_brightness(image, factor=1.2):\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def adjust_contrast(image, factor=1.2):\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def run_moe_with_tta(image_path, conf_threshold=0.3, iou_threshold=0.1):\n",
    "    original_img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_w, img_h = original_img.size\n",
    "    \n",
    "    augmentations = [\n",
    "        (\"original\", original_img),\n",
    "        (\"hflip\", horizontal_flip(original_img)),\n",
    "        (\"bright\", adjust_brightness(original_img, factor=1.2)),\n",
    "        (\"contrast\", adjust_contrast(original_img, factor=1.2)),\n",
    "    ]\n",
    "\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    for aug_name, aug_img in augmentations:\n",
    "        temp_path = f\"_temp_{aug_name}.jpg\"\n",
    "        aug_img.save(temp_path)\n",
    "\n",
    "        aug_boxes = run_moe(temp_path, conf_threshold=conf_threshold, iou_threshold=iou_threshold)\n",
    "        if aug_boxes:\n",
    "            boxes = aug_boxes[0].xyxy.cpu().numpy()\n",
    "            scores = aug_boxes[0].conf.cpu().numpy()\n",
    "            labels = aug_boxes[0].cls.cpu().numpy()\n",
    "\n",
    "            # Normalize box coordinates for WBF\n",
    "            norm_boxes = boxes.copy()\n",
    "            norm_boxes[:, [0,2]] /= img_w\n",
    "            norm_boxes[:, [1,3]] /= img_h\n",
    "\n",
    "            all_boxes.append(norm_boxes.tolist())\n",
    "            all_scores.append(scores.tolist())\n",
    "            all_labels.append(labels.tolist())\n",
    "\n",
    "        os.remove(temp_path)\n",
    "\n",
    "    if not all_boxes:\n",
    "        return []\n",
    "\n",
    "    # Apply Weighted Box Fusion\n",
    "    boxes_list, scores_list, labels_list = weighted_boxes_fusion(\n",
    "        all_boxes, all_scores, all_labels,\n",
    "        iou_thr=iou_threshold,\n",
    "        skip_box_thr=conf_threshold\n",
    "    )\n",
    "\n",
    "    # Rescale back to original image size\n",
    "    boxes_list = np.array(boxes_list)\n",
    "    boxes_list[:, [0,2]] *= img_w\n",
    "    boxes_list[:, [1,3]] *= img_h\n",
    "\n",
    "    final_tensor = torch.tensor(np.hstack([\n",
    "        boxes_list,                      # x1,y1,x2,y2\n",
    "        np.array(scores_list).reshape(-1,1),  # confidence\n",
    "        np.array(labels_list).reshape(-1,1)   # class (fire=0)\n",
    "    ]), dtype=torch.float32)\n",
    "\n",
    "    from ultralytics.engine.results import Boxes\n",
    "    kept_boxes = Boxes(final_tensor, orig_shape=original_img.size[::-1])  # height, width\n",
    "\n",
    "    return [kept_boxes]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
