{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491929a0",
   "metadata": {},
   "source": [
    "##  Baseline Mixture of Experts (MoE) Inference â€” Initial Version\n",
    "\n",
    "This notebook implements our **first version** of the **Mixture of Experts (MoE)** inference system for fire detection, before introducing any architectural or fusion improvements.\n",
    "\n",
    "###  Gating Network:\n",
    "- A **simple convolutional neural network (CNN)** is used as the gating module.\n",
    "- It takes the input image and predicts softmax weights for the 4 expert models, each trained on a different scenario (Outdoor, Indoor, FarField, Satellite).\n",
    "- These weights control how much influence each expert's prediction has during inference.\n",
    "\n",
    "###  Expert Models:\n",
    "- Four YOLOv8 models trained on different scene-specific datasets.\n",
    "- Each expert independently makes predictions on the same input image.\n",
    "\n",
    "###  Prediction Fusion:\n",
    "- After obtaining the weighted predictions from all experts, we combine their outputs using **traditional Non-Maximum Suppression (NMS)**.\n",
    "- NMS suppresses overlapping bounding boxes by retaining only the highest-confidence ones.\n",
    "\n",
    "###  Purpose of This Notebook:\n",
    "- Establish a **baseline MoE setup** without attention or advanced fusion techniques.\n",
    "- Serve as a comparison point for future iterations that include **attention-enhanced gating** and **Weighted Box Fusion (WBF)**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatingCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(GatingCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import nms\n",
    "from ultralytics.engine.results import Boxes\n",
    "\n",
    "def run_moe(image_path, conf_threshold=0.3, iou_threshold=0.5):\n",
    "    # Step 1: Preprocess the image\n",
    "    img_tensor = preprocess_image(image_path)\n",
    "    \n",
    "    # Step 2: Get expert weights from gating model\n",
    "    gate_weights = get_gate_weights(img_tensor)\n",
    "    # print(\"Gating weights:\", gate_weights)\n",
    "\n",
    "    all_boxes_raw = []\n",
    "\n",
    "    # Step 3: Run each expert and collect weighted predictions\n",
    "    for i, expert in enumerate(experts):\n",
    "        result = expert(image_path, verbose=False)[0]\n",
    "        weight = gate_weights[i]\n",
    "        if result.boxes is not None and result.boxes.conf is not None:\n",
    "            # Scale confidence by gating weight\n",
    "            conf = result.boxes.conf * weight\n",
    "            keep_mask = conf > conf_threshold\n",
    "\n",
    "            if keep_mask.sum() > 0:\n",
    "                xyxy = result.boxes.xyxy[keep_mask]\n",
    "                conf = conf[keep_mask]\n",
    "                cls = result.boxes.cls[keep_mask]\n",
    "\n",
    "                # Format: [x1, y1, x2, y2, conf, cls]\n",
    "                combined = torch.cat([xyxy, conf.unsqueeze(1), cls.unsqueeze(1)], dim=1)\n",
    "                all_boxes_raw.append(combined)\n",
    "\n",
    "    # Step 4: If no boxes from any expert, return empty\n",
    "    if not all_boxes_raw:\n",
    "        return []\n",
    "\n",
    "    # Step 5: Merge all boxes and apply NMS\n",
    "    all_boxes_combined = torch.cat(all_boxes_raw, dim=0)\n",
    "    boxes = all_boxes_combined[:, :4]\n",
    "    scores = all_boxes_combined[:, 4]\n",
    "    classes = all_boxes_combined[:, 5]\n",
    "\n",
    "    # Apply Non-Maximum Suppression\n",
    "    keep_indices = nms(boxes, scores, iou_threshold=iou_threshold)\n",
    "\n",
    "    final_kept = all_boxes_combined[keep_indices]\n",
    "    kept_boxes = Boxes(final_kept, orig_shape=result.orig_img.shape[:2])\n",
    "    \n",
    "    return [kept_boxes]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
